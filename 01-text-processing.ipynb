{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "from collections import Counter\n",
    "from stop_words import get_stop_words\n",
    "# from nltk.corpus import stopwords  # I DONT KNOW WHY BUT THIS IS NOT WORKING :(\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from proj_funs import extract_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = get_stop_words('english') \n",
    "STOP_WORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not contain non\n",
    "while \"non\" in STOP_WORDS: \n",
    "    STOP_WORDS.remove(\"non\")\n",
    "    print(\"non removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"openlibrary_works.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject extraction (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKS = len(df.index) # 50000\n",
    "\n",
    "print(\"Beginning subject extraction...\")\n",
    "subjects = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_subjects)(k, row, N_WORKS) for k, row in df[:N_WORKS].iterrows())\n",
    "subjects = np.concatenate(subjects, axis=0)\n",
    "print(\"Subject extraction complete.\")\n",
    "\n",
    "print(\"\\nSample result:\")\n",
    "subjects[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack arrays to one string\n",
    "subjects_str = ' '.join(np.ravel(subjects))\n",
    "print(\"Complete.\")\n",
    "\n",
    "# save as txt file\n",
    "text_file = open(\"allsubj_notrunc_100ksample.txt\", \"wt\")\n",
    "n = text_file.write(subjects_str)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the wordcloud object\n",
    "# https://stackoverflow.com/questions/59148244/keeping-words-together-in-wordcloud\n",
    "\n",
    "word_could_dict = Counter(subjects)\n",
    "wordcloud = WordCloud(background_color='white').generate_from_frequencies(word_could_dict)\n",
    "wordcloud.to_file(\"word_whole.png\")\n",
    "\n",
    "# plot the wordcloud object\n",
    "plt.imshow(wordcloud, interpolation='bilInear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of word frequencies\n",
    "sub_dictionary = word_could_dict\n",
    "# sort the dictionary\n",
    "word_freq = {k: v for k, v in sorted(\n",
    "    sub_dictionary.items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "# use words_ to print relative word frequencies\n",
    "rel_freq = wordcloud.words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freq_df = pd.DataFrame.from_dict(\n",
    "    rel_freq,\n",
    "    orient='index',\n",
    "    columns=[\"Freqency\"]\n",
    ")\n",
    "rel_freq_df['Subject'] = rel_freq_df.index\n",
    "rel_freq_df.reset_index(drop=True, inplace=True)\n",
    "rel_freq_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trucated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKS = len(df.index) # 50000\n",
    "\n",
    "print(\"Beginning subject extraction...\")\n",
    "subjects = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_subjects)(k, row, N_WORKS, collated = False) for k, row in df[:N_WORKS].iterrows())\n",
    "subjects = np.concatenate(subjects, axis=0)\n",
    "print(\"Subject extraction complete.\")\n",
    "\n",
    "print(\"\\nSample result:\")\n",
    "subjects[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_str = ' '.join(subjects)\n",
    "print(\"Complete.\")\n",
    "\n",
    "# save as txt file\n",
    "text_file = open(\"allsubj_split.txt\", \"wt\")\n",
    "n = text_file.write(subjects_str)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_str[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the wordcloud object\n",
    "# https://stackoverflow.com/questions/59148244/keeping-words-together-in-wordcloud\n",
    "\n",
    "word_could_dict = Counter(subjects)\n",
    "wordcloud = WordCloud(background_color='white').generate_from_frequencies(word_could_dict)\n",
    "wordcloud.to_file(\"word_trunc.png\")\n",
    "\n",
    "# plot the wordcloud object\n",
    "plt.imshow(wordcloud, interpolation='bilInear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of word frequencies\n",
    "sub_dictionary = wordcloud.process_text(subjects_str)\n",
    "# sort the dictionary\n",
    "word_freq = {k: v for k, v in sorted(\n",
    "    sub_dictionary.items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "# use words_ to print relative word frequencies\n",
    "rel_freq = wordcloud.words_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freq_df = pd.DataFrame.from_dict(\n",
    "    rel_freq,\n",
    "    orient='index',\n",
    "    columns=[\"Freqency\"]\n",
    ")\n",
    "rel_freq_df['Subject'] = rel_freq_df.index\n",
    "rel_freq_df.reset_index(drop=True, inplace=True)\n",
    "rel_freq_df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.histplot(data=rel_freq_df, x=\"Freqency\").set(xlim=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"Freqency\",\n",
    "    y=\"Subject\",\n",
    "    data=rel_freq_df[rel_freq_df[\"Freqency\"] > 0.1],\n",
    "    palette=\"Blues_r\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freq_df.to_csv(\"freq.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject Selection\n",
    "\n",
    "Preliminary subject genres are based on:\n",
    "Paper: http://cs231n.stanford.edu/reports/2017/pdfs/814.pdf\n",
    "Literature guide: https://blog.reedsy.com/book-genres/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_maps = {\n",
    "    \"fiction\" : [\"fiction\",\"fictitious\"],   # Fiction\n",
    "    \"fantasy\" : [\"fantasy\"],   # Fantasy/ Magical Realism\n",
    "    \"mystery\" : [\"mystery\",\"detective\"],   # Mystery/ Horror/ Thriller & Suspense - crime\n",
    "    \"romance\" : [\"romance\"],   # Romance\n",
    "    \"womens\" : [\"women\"],   # Women’s\n",
    "    \"grapic_novel\" : [\"grapic\",\"pictorial\",\"picture\"],   # Graphic Novel/ Comics\n",
    "    \"nonfiction\" : [\"nonfiction\"],   # Nonfiction\n",
    "    \"biography\" : [\"biography\"],   # Memoir & Autobiography/ Biography\n",
    "    \"dining\" : [\"dining\",\"cooking\",\"food\"],   # Food & Drink\n",
    "    \"art\" : [\"art\",\"poetry\",\"music\",\"architecture\",\"design\",\"arts\",\"picture\",\"photography\"],   # Art & Photography\n",
    "    \"history\" : [\"history\",\"war\",\"historical\",\"histoire\"],   # History\n",
    "    \"humor\" : [\"humor\"],   # Humor \n",
    "    \"religion\" : [\"religion\",\"church\",\"religious\",\"bible\",\"catholic\",\"christian\",\"christianity\",\"theology\"],   # Religion & Spirituality\n",
    "    \"social_sci\" : [\"culture\",\"sociology\",\"communication\",\"religious\",\"civilization\",\"public\",\"religion\",\"customs\",\"social\",\"criticism\",\"government\",\"politics\",\"war\",\"economic\",\"management\",\"world\",\"administration\"],   # Social Sciences\n",
    "    \"humanities\" : [\"ethics\",\"art\",\"arts\",\"customs\",\"culture\",\"behavior\",\"criticism\",\"language\",\"psychology\",\"philosophy\",\"therapy\"],\n",
    "    \"business\" : [\"business\", \"economic\",\"economics\",\"finance\",\"trade\",\"administration\",\"management\"],\n",
    "    \"politics\" : [\"government\",\"legislation\",\"military\",\"politics\",\"war\",\"economic\",\"law\",\"congresses\",\"political\",\"policy\",\"international\"],\n",
    "    \"sci_tech\" : [\"physics\",\"science\",\"chemistry\",\"mathematics\",\"research\",\"mathematical\",\"sciences\",\"computer\",\"computers\",\"industrial\",\"health\",\"medical\",\"engineering\",\"environmental\",\"architecture\",\"technology\"],   # Science & Technology\n",
    "    \"medicine\" : [\"medical\",\"diseases\",\"health\",\"disease\",\"medicine\",\"nursing\",\"animals\"],   # health & medicine\n",
    "    \"educational\" : [\"education\",\"guidebooks\",\"teaching\",\"study\",\"medical\",\"bibliography\",\"textbooks\",\"research\",\"manuals\",\"handbooks\",\"dictionaries\",\"theory\",\"animals\"],   # Education/ guide/ how-to\n",
    "    \"childrens\" : [\"childrens\",\"children\",\"family\",\"child\",\"nursery\",\"\",\"\"],   # Childrens\n",
    "    \"young_adult\" : [\"juvenile\"]   # YA\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cover(row):\n",
    "    # remove brackets\n",
    "    curr_covers = row[\"covers\"][1:-1].split(\", \")\n",
    "    # split into array of cover IDs\n",
    "    curr_covers = np.array(Parallel(n_jobs=-1)(delayed(int)(cover) for cover in curr_covers))\n",
    "\n",
    "    return(curr_covers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_1subject(curr_subjects, subj_map):\n",
    "    if any(x in curr_subjects for x in subj_map[1]): \n",
    "        return(subj_map[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_subjects(curr_subjects):\n",
    "    mapped_subjects = Parallel(n_jobs=-1)(delayed(map_1subject)(curr_subjects, subj_map) for subj_map in subj_maps.items())\n",
    "    while None in mapped_subjects: mapped_subjects.remove(None)\n",
    "    \n",
    "    return(mapped_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subj_cover_data(k, row, n_works = 4301727, report_freq=1*10**4):\n",
    "    curr_subjects = extract_subjects(row = row, collated=False)\n",
    "    cleaned_data = [row[\"key\"], get_cover(row), map_subjects(curr_subjects)]\n",
    "\n",
    "    # === PROGRESS REPORT === \n",
    "    if k % (report_freq) == 0:\n",
    "        print('{0:-8} / {1:}'.format(k, n_works))\n",
    "\n",
    "    return(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_data = Parallel(n_jobs=-1)(delayed(clean_subj_cover_data)(k, row) for k, row in df.iterrows())\n",
    "\n",
    "df_clean = pd.DataFrame(df_clean_data, columns= [\"key\",\"cover\", \"subjects\"])\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"df_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only works that have cover and subject\n",
    "df = df_clean\n",
    "df=df[df['subjects'].astype(bool)]\n",
    "# df_clean = df_clean[df_clean.all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new row for each cover\n",
    "df = df.reset_index(drop=True)\n",
    "lstcol = df.cover.values\n",
    "lstcollist = []\n",
    "indexlist = []\n",
    "countlist = []\n",
    "for ii in range(len(lstcol)):\n",
    "    lstcollist.extend(lstcol[ii])\n",
    "    indexlist.extend([ii]*len(lstcol[ii]))\n",
    "    countlist.extend([jj for jj in range(len(lstcol[ii]))])\n",
    "df = pd.merge(\n",
    "    df.drop(\"cover\",axis=1),\n",
    "    pd.DataFrame({\"cover\":lstcollist,\"lstcol_num\":countlist},index=indexlist),\n",
    "    left_index=True,right_index=True).reset_index(drop=True)\n",
    "\n",
    "df\n",
    "\n",
    "#REF\n",
    "# what is extend: https://stackoverflow.com/questions/252703/what-is-the-difference-between-pythons-list-methods-append-and-extend\n",
    "# ravel method from https://stackoverflow.com/questions/27263805/pandas-column-of-lists-create-a-row-for-each-list-element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.lstcol_num>0]\n",
    "df = df.drop([62]) # weird cover has -1 as cover number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_clean_extended.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE SHALL NOT USE EXTENDED BC OF RECURRING COVER IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_clean_extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"lstcol_num\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"lstcol_num\",\"Unnamed: 0\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_clean_uniqkey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subj viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of word frequencies\n",
    "subjs = [item for sublist in df.subjects.values for item in sublist]\n",
    "word_could_dict = Counter(subjs)\n",
    "wordcloud = WordCloud().generate_from_frequencies(word_could_dict)\n",
    "sub_dictionary = word_could_dict\n",
    "# sort the dictionary\n",
    "word_freq = {k: v for k, v in sorted(\n",
    "    sub_dictionary.items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "# use words_ to print relative word frequencies\n",
    "rel_freq = wordcloud.words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freq_df = pd.DataFrame.from_dict(\n",
    "    rel_freq,\n",
    "    orient='index',\n",
    "    columns=[\"Freqency\"]\n",
    ")\n",
    "rel_freq_df['Subject'] = rel_freq_df.index\n",
    "rel_freq_df.reset_index(drop=True, inplace=True)\n",
    "rel_freq_df\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "573805b6bf94dfdb6e23a5ddf9205e43e813018f3ce9b293891b8d65ab8de9da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
